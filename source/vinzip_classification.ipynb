{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   # 디렉토리 경로 호출 용도 \n",
    "import cv2   # 이미지 파일 불러올 때 사용\n",
    "import numpy as np  # 다양한 행렬 연산 (데이터 처리) 용도\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "# 데이터 전처리 (문자로된 폴더 리스트를 숫자형 array로 변환)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#one-hot-encoding을 위해 OneHotEncoder 함수를 불러옴\n",
    "from numpy import array # 리스트를 array형태로 만들떄 사용하는 함수\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습한 모델을 불러오기 위해 그래프를 만들어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\envs\\zz\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\pc\\Anaconda3\\envs\\zz\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-24709acabe26>:115: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()  # 이전에 생성해둔 graph, variable 모두 초기된다.\n",
    "\n",
    "TRAIN_DIR = 'E:\\\\data\\\\vinzip\\\\trainingSet\\\\'\n",
    "train_folder_list = array(os.listdir(TRAIN_DIR))\n",
    "train_input = []\n",
    "train_label = []\n",
    " \n",
    "label_encoder = LabelEncoder()  # LabelEncoder Class 호출\n",
    "\n",
    "integer_encoded = label_encoder.fit_transform(train_folder_list)  ###[0 1 2]\n",
    "\n",
    "#문자열로 구성된 train_folder_list를 숫자형 리스트로 변환\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "#print(onehot_encoder)\n",
    "#OneHotEncoder(categorical_features=None, categories=None,dtype=<class 'numpy.float64'>, handle_unknown='error', n_values=None, sparse=False)\n",
    "\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)  ## [[0][1][2]]\n",
    "\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)   ## [[1. 0. 0.] [0. 1. 0.] [0. 0. 1.]]\n",
    "\n",
    "\n",
    "for index in range(len(train_folder_list)):\n",
    "    path = os.path.join(TRAIN_DIR, train_folder_list[index])\n",
    "    path = path + '\\\\' \n",
    "    img_list = os.listdir(path) # <- img_1.jpg img_2.jpg....\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img) # E:\\data\\MNIST\\trainingSet\\0_zero\\ + img_1.jpg \n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) # 이미지를 불러옴\n",
    "        train_input.append([np.array(img)]) # 불러온 이미지를 array로 바꿔서 append\n",
    "        train_label.append([np.array(onehot_encoded[index])]) # one_hot 한 라벨도 append\n",
    "\n",
    "train_input = np.reshape(train_input, (-1,4096))  # (3800, 4096)\n",
    "train_label = np.reshape(train_label, (-1, 3))  # (3800, 3)\n",
    "\n",
    "train_input = np.array(train_input).astype(np.float32) # (3800, 4096) => 2차원 배열로 배열안에 각각 이미지가 행렬 형태로 저장됨\n",
    "train_label = np.array(train_label).astype(np.float32) # (3800,3) => 2차원 배열로 배열안에 라벨 값이 행렬 형태로 저장됨 [[0 0 1] [1 0 0 ]..]\n",
    "\n",
    "TEST_DIR ='E:\\\\data\\\\vinzip\\\\testSet\\\\'\n",
    "test_folder_list = array(os.listdir(TEST_DIR))\n",
    " \n",
    "test_input = []\n",
    "test_label = []\n",
    " \n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(test_folder_list)\n",
    " \n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    " \n",
    "for index in range(len(test_folder_list)):\n",
    "    path = os.path.join(TEST_DIR, test_folder_list[index])\n",
    "    path = path + '\\\\'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        test_input.append([np.array(img)])\n",
    "        test_label.append([np.array(onehot_encoded[index])])\n",
    " \n",
    "test_input = np.reshape(test_input, (-1, 4096))\n",
    "test_label = np.reshape(test_label, (-1, 3))\n",
    "test_input = np.array(test_input).astype(np.float32)\n",
    "test_label = np.array(test_label).astype(np.float32)\n",
    "# np.save(\"test_input.npy\",test_input)\n",
    "# np.save(\"test_label.npy\",test_label)\n",
    " \n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    " \n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 4096]) \n",
    "X_img = tf.reshape(X, [-1, 64, 64, 1])   # img 28x28x1 (black/white)\n",
    "\n",
    "Y = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    " \n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "# [64,64,1] --> [64,64,32] (32개의 featuremap을 가짐)\n",
    "\n",
    "L1 = tf.nn.relu(L1) # 활성화 함수는 렐루를 사용\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# [64,64,32] --> [32,32,32] (2x2 max_poo;ing을 거침)\n",
    "\n",
    "#L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "#L2 = tf.nn.dropout(L2, keep_prob)  #안쓰는게 더 정확함 \n",
    "\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 64], stddev=0.01))\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "L3_flat = tf.reshape(L3, [-1, 8 * 8 * 64]) # 다시 평평하게\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[8 * 8 * 64, 3], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                 \n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "#bias를 선언하여 b에 저장한다. output의 shape이 10이므로 shape을 10으로 설정\n",
    "logits = tf.matmul(L3_flat, W4) + b\n",
    "\n",
    "# define cost/loss &amp;amp;amp; optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    " #cost를 최소화하는 optimizer 함수를 선언\n",
    "    \n",
    "training_epochs = 100\n",
    "\n",
    "batch_size = 600\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지를 학습 시켰던 사이즈로 변환 (원본은 그대로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_size_img(path):\n",
    "    \n",
    "    img_size = 64\n",
    "    #path = '.\\\\vinzip_test\\\\'\n",
    "    dir_name = 'resize_img'\n",
    "    \n",
    "    img_type = '\\\\*.jpg'\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(path+dir_name)\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "    \n",
    "    imglist = glob.glob(path+img_type)\n",
    "\n",
    "    ## 이미지 사이즈 조절\n",
    "    for img_p in imglist:\n",
    "        img = Image.open(img_p)\n",
    "        img.resize((img_size,img_size)).save(path+dir_name+'\\\\'+img_p[(len(path)):])\n",
    "    \n",
    "    return imglist\n",
    "#re_size_img()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습시킨 모델에 이미지를 넣어 라벨값을 반환받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_return(TEST_DIR2):\n",
    "\n",
    "    #TEST_DIR2 ='E:\\\\data\\\\vinzip\\\\testSet2\\\\'\n",
    "    TEST_DIR2 = TEST_DIR2 + 'resize_img'\n",
    "\n",
    "    img_type = '\\\\*.jpg'\n",
    "    test_folder_list2 = glob.glob(TEST_DIR2+img_type)\n",
    "    \n",
    "    test_input2 = []\n",
    "    test_label2 = []\n",
    "\n",
    "    for index in range(len(test_folder_list2)):\n",
    "        path = os.path.join(TEST_DIR2, test_folder_list2[index])\n",
    "        print(path)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        test_input2.append([np.array(img)])\n",
    "\n",
    "    test_input2 = np.reshape(test_input2, (-1, 4096))\n",
    "    test_input2 = np.array(test_input2).astype(np.float32)\n",
    "    test_label2 = np.array(test_label2).astype(np.float32)\n",
    "\n",
    "\n",
    "    save_file = './train_model.ckpt'\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    out_lst=[]\n",
    "    # Launch the graph\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, save_file)\n",
    "\n",
    "        print(sess.run(tf.argmax(logits, 1),feed_dict={X: test_input2, keep_prob: 1}))\n",
    "        out_lst = sess.run(tf.argmax(logits, 1),feed_dict={X: test_input2, keep_prob: 1})\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(TEST_DIR2)\n",
    "    except OSError as e:\n",
    "        if e.errno == 2:\n",
    "        # 파일이나 디렉토리가 없음!\n",
    "            print('No such file or directory to remove')\n",
    "            pass\n",
    "        else:\n",
    "            print(e)\n",
    "\n",
    "    return out_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 각 라벨에 맞는 디렉토리로 이미지 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\data\\vinzip\\testSet2\\resize_img\\1568.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1569.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1570.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1571.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1572.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1573.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1574.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1575.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1576.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1577.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1578.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1579.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1580.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1581.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1582.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1583.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1584.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1585.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1586.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1587.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1588.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1589.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1590.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1591.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1592.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1593.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1594.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1595.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1596.jpg\n",
      "E:\\data\\vinzip\\testSet2\\resize_img\\1597.jpg\n",
      "INFO:tensorflow:Restoring parameters from ./train_model.ckpt\n",
      "[2 1 1 1 1 1 2 2 0 1 1 2 1 0 0 0 1 1 1 1 0 0 1 1 1 2 0 2 1 1]\n",
      "===# classification finish #===\n"
     ]
    }
   ],
   "source": [
    "from os import rename\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from os import remove\n",
    "from PIL import Image\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "\n",
    "TEST_DIR2 ='E:\\\\data\\\\vinzip\\\\testSet2\\\\'\n",
    "dir_name = 'classification_result\\\\'\n",
    "img = re_size_img(TEST_DIR2)\n",
    "out_lst =  model_return(TEST_DIR2)\n",
    "\n",
    "try:\n",
    "    os.mkdir(TEST_DIR2+dir_name)\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "\n",
    "## 디렉토리로 종류 분류 \n",
    "for i,v in enumerate(out_lst):\n",
    "    if v ==0:\n",
    "        try:\n",
    "            os.mkdir(TEST_DIR2+dir_name+'bottom')\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        rename(img[i],TEST_DIR2+dir_name+'bottom\\\\'+img[i][len(TEST_DIR2):])\n",
    "\n",
    "    elif v ==1:\n",
    "        try:\n",
    "            os.mkdir(TEST_DIR2+dir_name+'outer')\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        rename(img[i],TEST_DIR2+dir_name+'outer\\\\'+img[i][len(TEST_DIR2):])\n",
    "\n",
    "    elif v ==2:\n",
    "        try:\n",
    "            os.mkdir(TEST_DIR2+dir_name+'top')\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        rename(img[i],TEST_DIR2+dir_name+'top\\\\'+img[i][len(TEST_DIR2):])\n",
    "        \n",
    "print('===# classification finish #===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zz",
   "language": "python",
   "name": "zz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
